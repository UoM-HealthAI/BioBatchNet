{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# BioBatchNet Tutorial\n\nBioBatchNet is a deep learning framework for batch effect correction in biological data, supporting both single-cell RNA-seq (scRNA-seq) and Imaging Mass Cytometry (IMC) data.\n\nThis tutorial covers:\n1. Quick Start - Using the simple API\n2. Advanced Usage - Using models directly\n3. Custom Configuration - Adjusting model architecture and training parameters\n4. Real-world Examples"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Installation and Imports"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install the package (if not already installed)\n# !pip install biobatchnet\n\n# Or install from source\n# !git clone https://github.com/Manchester-HealthAI/BioBatchNet\n# !cd BioBatchNet && pip install -e ."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import necessary packages\nimport numpy as np\nimport pandas as pd\nimport torch\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n# Import BioBatchNet\nimport biobatchnet\nfrom biobatchnet import correct_batch_effects, IMCVAE, GeneVAE\n\nprint(f\"BioBatchNet version: {biobatchnet.__version__}\")\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Prepare Example Data"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate simulated data for demonstration\nnp.random.seed(42)\n\n# Simulate IMC data: 1000 cells, 40 protein markers, 3 batches\nn_cells = 1000\nn_features = 40\nn_batches = 3\n\n# Generate base data\nbase_data = np.random.randn(n_cells, n_features)\n\n# Add batch effects\nbatch_labels = np.random.choice(n_batches, n_cells)\nbatch_effects = np.zeros_like(base_data)\nfor i in range(n_batches):\n    batch_mask = batch_labels == i\n    # Add different shifts for each batch\n    batch_effects[batch_mask] = np.random.randn(1, n_features) * 0.5\n\n# Final data = base data + batch effects\ndata_with_batch = base_data + batch_effects\n\n# Convert to DataFrame\ndata_df = pd.DataFrame(\n    data_with_batch, \n    columns=[f'Protein_{i+1}' for i in range(n_features)]\n)\n\nbatch_df = pd.DataFrame({\n    'batch_id': batch_labels,\n    'cell_id': [f'cell_{i}' for i in range(n_cells)]\n})\n\nprint(f\"Data shape: {data_df.shape}\")\nprint(f\"Batch distribution: {np.bincount(batch_labels)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize batch effects\ndef plot_batch_effect(data, batch_labels, title):\n    \"\"\"Visualize batch effects using PCA\"\"\"\n    pca = PCA(n_components=2)\n    data_pca = pca.fit_transform(StandardScaler().fit_transform(data))\n    \n    plt.figure(figsize=(8, 6))\n    scatter = plt.scatter(data_pca[:, 0], data_pca[:, 1], \n                         c=batch_labels, cmap='viridis', alpha=0.6)\n    plt.colorbar(scatter, label='Batch')\n    plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')\n    plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n    plt.title(title)\n    plt.show()\n\n# Show batch effects in original data\nplot_batch_effect(data_with_batch, batch_labels, 'Original Data (with batch effects)')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Method 1: Using the Simple API (Recommended)\n\nThis is the easiest way to use BioBatchNet, suitable for most users."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Batch effect correction with default parameters\nbio_embeddings, batch_embeddings = correct_batch_effects(\n    data=data_df,           # Expression data\n    batch_info=batch_df,    # Batch information\n    batch_key='batch_id',   # Batch column name\n    data_type='imc',        # Data type: 'imc' or 'scrna'\n    latent_dim=20,          # Latent space dimension\n    epochs=100              # Training epochs\n)\n\nprint(f\"Biological embedding shape: {bio_embeddings.shape}\")\nprint(f\"Batch embedding shape: {batch_embeddings.shape}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize corrected data\nplot_batch_effect(bio_embeddings, batch_labels, 'Corrected Biological Embeddings')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 3.1 Custom Loss Weights\n\nAdjust loss weights based on your data characteristics."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Custom loss weights\ncustom_loss_weights = {\n    'recon_loss': 10,      # Reconstruction loss weight\n    'discriminator': 0.3,   # Discriminator loss weight\n    'classifier': 1,        # Classifier loss weight\n    'kl_loss_1': 0.005,    # KL divergence loss 1\n    'kl_loss_2': 0.1,      # KL divergence loss 2\n    'ortho_loss': 0.01     # Orthogonality loss weight\n}\n\nbio_embeddings_custom, batch_embeddings_custom = correct_batch_effects(\n    data=data_df,\n    batch_info=batch_df,\n    batch_key='batch_id',\n    data_type='imc',\n    latent_dim=20,\n    epochs=100,\n    loss_weights=custom_loss_weights  # Use custom weights\n)\n\nprint(\"Training completed with custom loss weights\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 3.2 Automatic Parameter Adjustment for Different Batch Counts\n\nThe API automatically adjusts parameters based on the number of batches."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Simulate data with different batch counts\ndef test_different_batch_counts():\n    for n_batches in [3, 15, 35]:\n        # Create test data\n        test_batch_labels = np.random.choice(n_batches, n_cells)\n        test_batch_df = pd.DataFrame({'batch_id': test_batch_labels})\n        \n        print(f\"\\nNumber of batches: {n_batches}\")\n        print(\"API will automatically select appropriate loss weights\")\n        \n        # API automatically adjusts parameters\n        bio_emb, batch_emb = correct_batch_effects(\n            data=data_df,\n            batch_info=test_batch_df,\n            data_type='imc',\n            epochs=50  # Fewer epochs for demonstration\n        )\n        \n        print(f\"Complete! Embedding dimensions: {bio_emb.shape}\")\n\n# test_different_batch_counts()  # Uncomment to run"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Method 2: Using Models Directly (Advanced)\n\nFor more control, use the model classes directly."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create IMCVAE model instance\nmodel = IMCVAE(\n    in_sz=n_features,                              # Input dimension\n    out_sz=n_features,                             # Output dimension  \n    latent_sz=20,                                  # Latent space dimension\n    num_batch=n_batches,                           # Number of batches\n    bio_encoder_hidden_layers=[512, 1024, 1024],   # Bio encoder architecture\n    batch_encoder_hidden_layers=[256],             # Batch encoder architecture\n    decoder_hidden_layers=[1024, 1024, 512],       # Decoder architecture\n    batch_classifier_layers_power=[512, 1024, 1024], # Strong classifier architecture\n    batch_classifier_layers_weak=[128]             # Weak classifier architecture\n)\n\nprint(f\"Model parameter count: {sum(p.numel() for p in model.parameters()):,}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train the model\nmodel.fit(\n    data=data_df.values,\n    batch_info=batch_labels,\n    epochs=100,\n    lr=1e-3,\n    batch_size=256,\n    device='cuda' if torch.cuda.is_available() else 'cpu'\n)\n\nprint(\"Model training complete\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get corrected embeddings\nbio_embeddings_direct = model.get_bio_embeddings(data_df.values)\nprint(f\"Biological embedding shape: {bio_embeddings_direct.shape}\")\n\n# Or get both biological and batch embeddings\nbio_emb, batch_emb = model.correct_batch_effects(data_df.values)\nprint(f\"Biological embeddings: {bio_emb.shape}, Batch embeddings: {batch_emb.shape}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Method 3: Using GeneVAE for scRNA-seq Data\n\nGeneVAE is specifically designed for single-cell RNA-seq data."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Simulate scRNA-seq data\nn_cells_rna = 5000\nn_genes = 2000\nn_batches_rna = 4\n\n# Generate sparse gene expression data (simulating dropout)\nrna_data = np.random.negative_binomial(5, 0.3, size=(n_cells_rna, n_genes))\nrna_data = rna_data.astype(np.float32)\n\n# Add batch effects\nrna_batch_labels = np.random.choice(n_batches_rna, n_cells_rna)\nfor i in range(n_batches_rna):\n    mask = rna_batch_labels == i\n    rna_data[mask] *= np.random.uniform(0.8, 1.2)  # Batch-specific scaling\n\nprint(f\"scRNA-seq data shape: {rna_data.shape}\")\nprint(f\"Zero proportion: {(rna_data == 0).mean():.2%}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Process scRNA-seq data using the API\nbio_emb_rna, batch_emb_rna = correct_batch_effects(\n    data=rna_data,\n    batch_info=rna_batch_labels,\n    data_type='scrna',  # Specify scRNA-seq data\n    latent_dim=30,      # Usually scRNA needs higher latent dimension\n    epochs=100\n)\n\nprint(f\"scRNA embedding shape: {bio_emb_rna.shape}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Using GeneVAE model directly\ngene_model = GeneVAE(\n    in_sz=n_genes,\n    out_sz=n_genes,\n    latent_sz=30,\n    num_batch=n_batches_rna,\n    bio_encoder_hidden_layers=[500, 2000, 2000],   # Default scRNA architecture\n    batch_encoder_hidden_layers=[500],\n    decoder_hidden_layers=[2000, 2000, 500],\n    batch_classifier_layers_power=[500, 2000, 2000],\n    batch_classifier_layers_weak=[128]\n)\n\n# Custom loss weights for scRNA-seq\nscrna_loss_weights = {\n    'recon_loss': 10,\n    'discriminator': 0.04,\n    'classifier': 1,\n    'kl_loss_1': 1e-7,\n    'kl_loss_2': 0.01,\n    'ortho_loss': 0.0002,\n    'mmd_loss_1': 0,\n    'kl_loss_size': 0.002  # scRNA-specific size factor KL loss\n}\n\ngene_model.fit(\n    data=rna_data,\n    batch_info=rna_batch_labels,\n    epochs=100,\n    loss_weights=scrna_loss_weights\n)\n\nprint(\"GeneVAE model training complete\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Advanced Configuration and Tuning Tips"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Advanced configuration example\nadvanced_config = {\n    # Data parameters\n    'data': data_df,\n    'batch_info': batch_df,\n    'batch_key': 'batch_id',\n    'data_type': 'imc',\n    \n    # Model architecture parameters\n    'latent_dim': 25,\n    'bio_encoder_hidden_layers': [256, 512, 512],  # Custom encoder architecture\n    'batch_encoder_hidden_layers': [128, 128],     # Two-layer batch encoder\n    'decoder_hidden_layers': [512, 512, 256],      # Custom decoder\n    \n    # Training parameters\n    'epochs': 150,\n    'lr': 5e-4,           # Learning rate\n    'batch_size': 128,    # Batch size\n    \n    # Loss weights\n    'loss_weights': {\n        'recon_loss': 15,\n        'discriminator': 0.2,\n        'classifier': 1.5,\n        'kl_loss_1': 0.001,\n        'kl_loss_2': 0.05,\n        'ortho_loss': 0.02\n    }\n}\n\n# Use advanced configuration\nbio_emb_advanced, batch_emb_advanced = correct_batch_effects(**advanced_config)\nprint(\"Advanced configuration training complete\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Evaluate Batch Correction Performance"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from sklearn.metrics import silhouette_score\nfrom scipy.stats import f_oneway\n\ndef evaluate_batch_correction(original_data, corrected_data, batch_labels):\n    \"\"\"\n    Evaluate batch correction performance\n    \"\"\"\n    # 1. Silhouette coefficient (lower is better for batch mixing)\n    sil_original = silhouette_score(original_data, batch_labels)\n    sil_corrected = silhouette_score(corrected_data, batch_labels)\n    \n    print(f\"Silhouette coefficient (batch separation, lower is better):\")\n    print(f\"  Original data: {sil_original:.4f}\")\n    print(f\"  Corrected: {sil_corrected:.4f}\")\n    print(f\"  Improvement: {(sil_original - sil_corrected) / sil_original * 100:.1f}%\\n\")\n    \n    # 2. ANOVA F-statistic (lower is better for less batch difference)\n    groups_original = [original_data[batch_labels == i] for i in range(len(np.unique(batch_labels)))]\n    groups_corrected = [corrected_data[batch_labels == i] for i in range(len(np.unique(batch_labels)))]\n    \n    # Calculate F-statistic for first 5 features\n    f_stats_original = []\n    f_stats_corrected = []\n    \n    n_features_to_test = min(5, original_data.shape[1])\n    for i in range(n_features_to_test):\n        f_orig, _ = f_oneway(*[g[:, i] for g in groups_original])\n        f_corr, _ = f_oneway(*[g[:, i] for g in groups_corrected])\n        f_stats_original.append(f_orig)\n        f_stats_corrected.append(f_corr)\n    \n    print(f\"Mean F-statistic (batch difference, lower is better):\")\n    print(f\"  Original data: {np.mean(f_stats_original):.4f}\")\n    print(f\"  Corrected: {np.mean(f_stats_corrected):.4f}\")\n    print(f\"  Improvement: {(np.mean(f_stats_original) - np.mean(f_stats_corrected)) / np.mean(f_stats_original) * 100:.1f}%\")\n    \n    return sil_corrected, np.mean(f_stats_corrected)\n\n# Evaluate correction performance\nprint(\"=\" * 50)\nprint(\"Batch Correction Performance Evaluation\")\nprint(\"=\" * 50)\nevaluate_batch_correction(data_with_batch, bio_embeddings, batch_labels)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Visualization Comparison"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create comparison visualization\nfig, axes = plt.subplots(1, 2, figsize=(15, 6))\n\n# Original data PCA\npca_original = PCA(n_components=2)\ndata_pca_original = pca_original.fit_transform(StandardScaler().fit_transform(data_with_batch))\n\n# Corrected data PCA\npca_corrected = PCA(n_components=2)\ndata_pca_corrected = pca_corrected.fit_transform(StandardScaler().fit_transform(bio_embeddings))\n\n# Plot original data\nscatter1 = axes[0].scatter(data_pca_original[:, 0], data_pca_original[:, 1],\n                           c=batch_labels, cmap='viridis', alpha=0.6, s=20)\naxes[0].set_xlabel(f'PC1 ({pca_original.explained_variance_ratio_[0]:.2%})')\naxes[0].set_ylabel(f'PC2 ({pca_original.explained_variance_ratio_[1]:.2%})')\naxes[0].set_title('Original Data (with batch effects)')\naxes[0].legend(*scatter1.legend_elements(), title=\"Batch\", loc=\"best\")\n\n# Plot corrected data\nscatter2 = axes[1].scatter(data_pca_corrected[:, 0], data_pca_corrected[:, 1],\n                           c=batch_labels, cmap='viridis', alpha=0.6, s=20)\naxes[1].set_xlabel(f'PC1 ({pca_corrected.explained_variance_ratio_[0]:.2%})')\naxes[1].set_ylabel(f'PC2 ({pca_corrected.explained_variance_ratio_[1]:.2%})')\naxes[1].set_title('After BioBatchNet Correction')\naxes[1].legend(*scatter2.legend_elements(), title=\"Batch\", loc=\"best\")\n\nplt.suptitle('Before and After Batch Effect Correction', fontsize=16, y=1.02)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 9. Save and Load Models"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save trained model\nmodel_path = 'biobatchnet_model.pt'\ntorch.save({\n    'model_state_dict': model.state_dict(),\n    'model_config': {\n        'in_sz': n_features,\n        'out_sz': n_features,\n        'latent_sz': 20,\n        'num_batch': n_batches,\n        'bio_encoder_hidden_layers': [512, 1024, 1024],\n        'batch_encoder_hidden_layers': [256],\n        'decoder_hidden_layers': [1024, 1024, 512],\n        'batch_classifier_layers_power': [512, 1024, 1024],\n        'batch_classifier_layers_weak': [128]\n    }\n}, model_path)\n\nprint(f\"Model saved to {model_path}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load model\ncheckpoint = torch.load(model_path, map_location='cpu')\nconfig = checkpoint['model_config']\n\n# Recreate model\nloaded_model = IMCVAE(**config)\nloaded_model.load_state_dict(checkpoint['model_state_dict'])\nloaded_model.eval()\n\nprint(\"Model loaded successfully\")\n\n# Use loaded model for prediction\nwith torch.no_grad():\n    bio_emb_loaded = loaded_model.get_bio_embeddings(data_df.values)\n    print(f\"Loaded model prediction shape: {bio_emb_loaded.shape}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 10. Common Questions and Tuning Suggestions\n\n### 10.1 How to choose latent dimension (latent_dim)?\n- IMC data: typically 15-25 dimensions\n- scRNA-seq data: typically 20-50 dimensions\n- Can be selected via cross-validation\n\n### 10.2 Loss weight adjustment strategies\n- **recon_loss**: Reconstruction quality, typically set to 10\n- **discriminator**: Batch mixing degree, reduce for many batches (0.1-0.3)\n- **classifier**: Batch information retention, typically set to 1\n- **kl_loss**: Regularization strength, increase when overfitting\n- **ortho_loss**: Orthogonality constraint, keep default\n\n### 10.3 What if training is unstable?\n- Reduce learning rate\n- Decrease batch_size\n- Adjust loss weights\n- Increase training epochs\n\n### 10.4 What if memory is insufficient?\n- Reduce batch_size\n- Use CPU training: device='cpu'\n- Reduce model complexity (fewer hidden layer nodes)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 11. Real Data Example (Using AnnData)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# If you have real h5ad files\nimport anndata as ad\n\n# Example: Load and process real data\n\"\"\"\n# Load AnnData object\nadata = ad.read_h5ad('your_data.h5ad')\n\n# Extract data and batch information\nif hasattr(adata.X, 'toarray'):\n    X = adata.X.toarray()  # If sparse matrix\nelse:\n    X = adata.X\n\nbatch_labels = adata.obs['batch'].values\n\n# Batch effect correction\nbio_embeddings, _ = correct_batch_effects(\n    data=X,\n    batch_info=batch_labels,\n    data_type='scrna',  # or 'imc'\n    epochs=200\n)\n\n# Store results back to AnnData\nadata.obsm['X_biobatchnet'] = bio_embeddings\n\n# Save results\nadata.write('corrected_data.h5ad')\n\"\"\"\n\nprint(\"Real data processing workflow example (requires h5ad file)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nBioBatchNet provides flexible batch effect correction solutions:\n\n1. **Simple API** (`correct_batch_effects`): Suitable for quick use with automatic parameter selection\n2. **Model Classes** (`IMCVAE`, `GeneVAE`): Provide more control for advanced users\n3. **Custom Configuration**: Adjust model architecture, loss weights, and other parameters\n\n### Key Features:\n- Supports both IMC and scRNA-seq data types\n- Automatically adjusts parameters based on batch count\n- Customizable model architecture and training parameters\n- Provides both biological and batch embedding outputs\n\n### Best Practices:\n1. Start with default parameters\n2. Adjust loss weights based on results\n3. Adjust model architecture if necessary\n4. Use evaluation metrics to validate performance\n\nFor more information, see:\n- GitHub: https://github.com/Manchester-HealthAI/BioBatchNet\n- Documentation: USAGE.md"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}